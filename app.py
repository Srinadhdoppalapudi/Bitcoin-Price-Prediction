# ===============================================================
# BITCOIN PRICE PREDICTION ‚Äì STREAMLIT WEB APPLICATION
# ===============================================================

import os

from numpy.lib.recfunctions import join_by

os.environ["OMP_NUM_THREADS"] = "1"
os.environ["TF_NUM_INTRAOP_THREADS"] = "1"
os.environ["TF_NUM_INTEROP_THREADS"] = "1"

import streamlit as st
import numpy as np
import pandas as pd
import pickle
import plotly.graph_objects as go
import tensorflow as tf   # ‚úÖ FORCE TensorFlow Keras

# -------------------------------------------------------
# PAGE CONFIG
# -------------------------------------------------------
st.set_page_config(
    page_title="Bitcoin Price Prediction",
    layout="wide"
)

# -------------------------------------------------------
# FILE PATHS
# -------------------------------------------------------
BASE_DIR = os.path.dirname(os.path.abspath(__file__))

MODEL_PATH = os.path.join(BASE_DIR, "btc_webapp", "model", "lstm_model.h5")
SCALER_PATH = os.path.join(BASE_DIR, "btc_webapp", "model", "scaler.pkl")
LAST60_PATH = os.path.join(BASE_DIR, "btc_webapp", "model", "last_60_scaled.npy")
HISTORY_PATH = os.path.join(BASE_DIR, "btc_webapp", "model", "btc_history.csv")
TRAINING_HISTORY = os.path.join(BASE_DIR, "btc_webapp", "model", "training_history.csv")


TIME_STEP = 60

# -------------------------------------------------------
# LAZY LOAD RESOURCES (CRITICAL FIX)
# -------------------------------------------------------
@st.cache_resource
def load_resources():
    model = tf.keras.models.load_model(MODEL_PATH, compile=False)
    with open(SCALER_PATH, "rb") as f:
        scaler = pickle.load(f)
    last_60 = np.load(LAST60_PATH).reshape(60,)
    return model, scaler, last_60

# -------------------------------------------------------
# SIDEBAR NAVIGATION
# -------------------------------------------------------
st.sidebar.title("Navigation")
page = st.sidebar.radio(
    "Go to",
    [
        "Instructions",
        "Interactive Prediction",
        "Price History",
        "Training Curve",
        "Analysis Dashboard",
        "Model Insights"   # ‚úÖ THIS LINE WAS MISSING
    ]
)


# =======================================================
# INSTRUCTIONS
# =======================================================
if page == "Instructions":
    st.title("üìò Bitcoin Price Prediction Using LSTM")

    st.markdown("""
### üìå Overview

This project implements an end-to-end system for predicting future **Bitcoin closing prices**
using a **Long Short-Term Memory (LSTM)** neural network.  
It was developed as part of a data analytics project and demonstrates the full data science lifecycle, including:

- Data collection  
- Preprocessing  
- Model development  
- Evaluation  
- Deployment as an interactive **Streamlit web application**

The Streamlit interface allows users to explore historical trends, visualize model performance,
and generate future price forecasts through an intuitive dashboard.

---

### üìä Data Source and Preprocessing

**Data Source:** Yahoo Finance (BTC-USD)

**Dataset Coverage:**  
- January 1, 2018 ‚Äì November 16, 2025  

**Selected Modeling Period:**  
- August 31, 2021 ‚Äì November 16, 2025  

**Number of Observations:**  
- 1,539 daily records  

**Preprocessing Steps:**
- Selected Date and Close price columns  
- Cleaned column names and inconsistencies  
- Converted Date to datetime format and sorted chronologically  
- Applied **MinMaxScaler** for normalization  
- Created **60-day sliding window sequences**  
- Split data into **80% training** and **20% testing**

---

### üß† Model Architecture

The forecasting model uses a stacked **LSTM architecture** optimized for time-series prediction:

- Input shape: **(60 time steps, 1 feature)**
- LSTM layer with **50 units** (returns sequences)
- Dropout layer (**0.2**)
- LSTM layer with **30 units**
- Dense output layer (1 neuron)

**Training Configuration:**
- Loss Function: Mean Squared Error (MSE)
- Optimizer: Adam
- Batch Size: 32
- Maximum Epochs: 200
- Early stopping to prevent overfitting

---

### üìà Model Evaluation and Results

The model was evaluated on unseen test data using standard regression metrics:

- Mean Squared Error (MSE)
- Root Mean Squared Error (RMSE)
- Mean Absolute Error (MAE)
- Explained Variance
- R¬≤ Score

 **Key Results (Test Set):**
- **R¬≤ Score:** 0.9502  
- **Explained Variance:** 0.9503  

These results indicate that the model explains over **95% of the variance**
in Bitcoin closing prices.

---

### üîÆ Future Price Forecasting

The trained model generates multi-day forecasts by iteratively feeding predicted values
back into the 60-day input window.

**Observations:**
- Smooth and stable forecast trends  
- No unrealistic spikes  
- Predictions align with recent market behavior  

---

### üîç Comparison with Traditional Methods

The LSTM model was qualitatively compared with:

- Moving Average  
- Linear Regression  
- ARIMA  

Traditional models struggled with Bitcoin‚Äôs nonlinear behavior,
while the LSTM model performed significantly better due to its ability
to capture long-term temporal dependencies.

---

### üõ†Ô∏è Technology Stack

- **Programming Language:** Python  
- **Web Framework:** Streamlit  
- **Deep Learning:** TensorFlow / Keras  
- **Data Processing:** NumPy, Pandas  
- **Scaling:** scikit-learn (MinMaxScaler)  
- **Visualization:** Plotly, Matplotlib  
    """)


# =======================================================
# INTERACTIVE PREDICTION
# =======================================================
elif page == "Interactive Prediction":
    st.title("üîÆ Predict Future Bitcoin Prices")

    days = st.number_input(
        "Enter number of days to predict (1‚Äì365):",
        min_value=1,
        max_value=365,
        value=30
    )

    if st.button("Predict"):
        model, scaler, last_60 = load_resources()

        df_hist = pd.read_csv(HISTORY_PATH)
        df_hist["Date"] = pd.to_datetime(df_hist["Date"])
        last_date = df_hist["Date"].max()

        future_dates = pd.date_range(
            start=last_date + pd.Timedelta(days=1),
            periods=days
        )

        temp_input = list(last_60)
        predictions = []

        for _ in range(days):
            x_input = np.array(temp_input[-TIME_STEP:]).reshape(1, TIME_STEP, 1)
            yhat = model.predict(x_input, verbose=0)
            temp_input.append(float(yhat[0][0]))
            predictions.append(float(yhat[0][0]))

        final_pred = scaler.inverse_transform(
            np.array(predictions).reshape(-1, 1)
        ).flatten()

        st.success(f"Latest Predicted Price: ${final_pred[-1]:,.2f}")

        fig = go.Figure()
        fig.add_trace(go.Scatter(
            x=future_dates,
            y=final_pred,
            mode="lines+markers",
            name="Predicted Price"
        ))

        fig.update_layout(
            title="Bitcoin Price Forecast",
            xaxis_title="Date",
            yaxis_title="Price (USD)"
        )

        st.plotly_chart(fig, use_container_width=True)

# =======================================================
# PRICE HISTORY
# =======================================================
elif page == "Price History":
    st.title("üìà Bitcoin Price History")

    df = pd.read_csv(HISTORY_PATH)
    df["Date"] = pd.to_datetime(df["Date"])
    close_col = [c for c in df.columns if "close" in c.lower()][0]

    fig = go.Figure()
    fig.add_trace(go.Scatter(
        x=df["Date"],
        y=df[close_col],
        mode="lines",
        name="Close Price"
    ))

    fig.update_layout(
        title="Historical Bitcoin Closing Price",
        xaxis_title="Date",
        yaxis_title="USD"
    )

    st.plotly_chart(fig, use_container_width=True)

# =======================================================
# TRAINING CURVE
# =======================================================
elif page == "Training Curve":
    st.title("üìä Training vs Validation Loss")

    df = pd.read_csv(TRAINING_HISTORY)

    fig = go.Figure()
    fig.add_trace(go.Scatter(y=df["loss"], name="Training Loss"))
    fig.add_trace(go.Scatter(y=df["val_loss"], name="Validation Loss"))

    fig.update_layout(
        title="Model Training Performance",
        xaxis_title="Epochs",
        yaxis_title="Loss"
    )

    st.plotly_chart(fig, use_container_width=True)

# =======================================================
# ANALYSIS DASHBOARD (‚úÖ ALL 3 CHARTS)
# =======================================================
elif page == "Analysis Dashboard":
    st.title("üìä Bitcoin Market Analysis")

    df = pd.read_csv(HISTORY_PATH)
    df["Date"] = pd.to_datetime(df["Date"])
    df["Month"] = df["Date"].dt.to_period("M").astype(str)

    # 1Ô∏è‚É£ Full OHLC chart
    fig1 = go.Figure()
    for col in ["Open", "High", "Low", "Close"]:
        fig1.add_trace(go.Scatter(x=df["Date"], y=df[col], name=col))
    fig1.update_layout(title="Bitcoin OHLC Analysis")
    st.plotly_chart(fig1, use_container_width=True)

    # 2Ô∏è‚É£ Monthly High vs Low
    monthly_hl = df.groupby("Month").agg({"High": "max", "Low": "min"}).reset_index()

    fig2 = go.Figure()
    fig2.add_bar(x=monthly_hl["Month"], y=monthly_hl["High"], name="High")
    fig2.add_bar(x=monthly_hl["Month"], y=monthly_hl["Low"], name="Low")
    fig2.update_layout(barmode="group", title="Monthly High vs Low")
    st.plotly_chart(fig2, use_container_width=True)

    # 3Ô∏è‚É£ Monthly Open vs Close ‚úÖ (RESTORED)
    monthly_oc = df.groupby("Month").agg({"Open": "mean", "Close": "mean"}).reset_index()

    fig3 = go.Figure()
    fig3.add_bar(x=monthly_oc["Month"], y=monthly_oc["Open"], name="Open")
    fig3.add_bar(x=monthly_oc["Month"], y=monthly_oc["Close"], name="Close")
    fig3.update_layout(barmode="group", title="Monthly Open vs Close")
    st.plotly_chart(fig3, use_container_width=True)


# =======================================================
# MODEL INSIGHTS & INTERPRETATION DASHBOARD
# =======================================================
elif page == "Model Insights":
    st.title("üß† Model Insights & Interpretation")

    st.markdown("""
    This section provides **deeper insights into the LSTM model‚Äôs behavior**, 
    prediction uncertainty, and limitations.  
    It is designed to support **academic interpretation**, not financial advice.
    """)

    # ---------------------------------------------------
    # LOAD DATA & MODEL
    # ---------------------------------------------------
    model, scaler, last_60 = load_resources()

    df = pd.read_csv(HISTORY_PATH)
    df["Date"] = pd.to_datetime(df["Date"])

    close_col = [c for c in df.columns if "close" in c.lower()][0]
    actual_prices = df[close_col].values

    # ---------------------------------------------------
    # GENERATE TEST SET PREDICTIONS FOR ERROR ANALYSIS
    # ---------------------------------------------------
    scaled_prices = scaler.transform(actual_prices.reshape(-1, 1))

    X, y = [], []
    for i in range(TIME_STEP, len(scaled_prices)):
        X.append(scaled_prices[i - TIME_STEP:i, 0])
        y.append(scaled_prices[i, 0])

    X = np.array(X).reshape(-1, TIME_STEP, 1)
    y = np.array(y)

    preds_scaled = model.predict(X, verbose=0).flatten()
    preds = scaler.inverse_transform(preds_scaled.reshape(-1, 1)).flatten()
    y_true = scaler.inverse_transform(y.reshape(-1, 1)).flatten()

    residuals = y_true - preds

    # ===================================================
    # SECTION 1: PREDICTION CONFIDENCE BAND
    # ===================================================
    st.subheader("üìà Prediction Confidence Band")

    future_days = 60
    future_dates = pd.date_range(
        start=df["Date"].max() + pd.Timedelta(days=1),
        periods=future_days
    )

    temp_input = list(last_60)
    future_preds = []

    for _ in range(future_days):
        x_input = np.array(temp_input[-TIME_STEP:]).reshape(1, TIME_STEP, 1)
        yhat = model.predict(x_input, verbose=0)[0][0]
        temp_input.append(yhat)
        future_preds.append(yhat)

    future_prices = scaler.inverse_transform(
        np.array(future_preds).reshape(-1, 1)
    ).flatten()

    std_dev = np.std(residuals)

    upper_band = future_prices + std_dev
    lower_band = future_prices - std_dev

    fig_conf = go.Figure()
    fig_conf.add_trace(go.Scatter(
        x=future_dates, y=future_prices,
        mode="lines", name="Predicted Price"
    ))
    fig_conf.add_trace(go.Scatter(
        x=future_dates, y=upper_band,
        mode="lines", line=dict(dash="dash"),
        name="Upper Confidence"
    ))
    fig_conf.add_trace(go.Scatter(
        x=future_dates, y=lower_band,
        mode="lines", line=dict(dash="dash"),
        name="Lower Confidence"
    ))

    fig_conf.update_layout(
        title="Future Price Forecast with Confidence Range",
        xaxis_title="Date",
        yaxis_title="Price (USD)"
    )

    st.plotly_chart(fig_conf, use_container_width=True)

    st.markdown("""
    **Interpretation:**  
    The dashed lines represent uncertainty around predictions.  
    As the forecast horizon increases, uncertainty also grows.
    """)

    # ===================================================
    # SECTION 2: ERROR DISTRIBUTION
    # ===================================================
    st.subheader("üìâ Prediction Error Analysis")

    fig_err = go.Figure()
    fig_err.add_histogram(
        x=residuals,
        nbinsx=50,
        name="Residuals"
    )

    fig_err.update_layout(
        title="Distribution of Prediction Errors (Residuals)",
        xaxis_title="Prediction Error (USD)",
        yaxis_title="Frequency"
    )

    st.plotly_chart(fig_err, use_container_width=True)

    st.markdown("""
    **Observation:** 
    Errors are centered near zero, indicating stable predictions 
    with no major systematic bias.
    """)

    # ===================================================
    # SECTION 3: MODEL STRENGTHS & LIMITATIONS
    # ===================================================
    st.subheader(" Model Strengths &  Limitations")

    col1, col2 = st.columns(2)

    with col1:
        st.markdown("""
        ### Strengths
        - Captures nonlinear temporal patterns  
        - Strong performance on recent historical trends  
        - High R¬≤ and explained variance  
        - Robust against short-term noise  
        """)

    with col2:
        st.markdown("""
        ###  Limitations
        - Assumes historical patterns persist  
        - Cannot incorporate news or macroeconomic events  
        - Sensitive to extreme market shocks  
        - Not suitable for high-frequency trading  
        """)

    # ===================================================
    # SECTION 4: RESPONSIBLE USE NOTICE
    # ===================================================
    st.subheader("‚öñÔ∏è Responsible & Ethical Use")

    st.info("""
    This application is intended **strictly for educational and analytical purposes**.

    - Predictions are **not financial advice**
    - Cryptocurrency markets are highly volatile
    - External factors (news, policy, sentiment) are not modeled
    """)

    # ===================================================
    # SECTION 5: STUDENT REFLECTION
    # ===================================================
    st.subheader("üìò Student Reflection")

    st.markdown("""
    During this project, I learned how deep-learning models like LSTM can effectively 
    capture long-term dependencies in financial time-series data. 

    While the model performs well on historical trends, it also highlighted the 
    importance of understanding uncertainty, model limitations, and ethical use. 
    Given more time, incorporating external signals such as trading volume, 
    sentiment analysis, or macroeconomic indicators could further improve performance.
    """)


